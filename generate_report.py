# -*- coding: utf-8 -*-
"""
ç¨ç«‹å ±å‘Šç”Ÿæˆå™¨ (V16 - æ¨¡çµ„åŒ–)

é€™å€‹è…³æœ¬æ˜¯ä¸€å€‹ç¨ç«‹çš„å·¥å…·ï¼Œå°ˆé–€ç”¨ä¾†å¾ SQLite è³‡æ–™åº«ç”Ÿæˆæ¨™æº–çš„ Markdown å ±å‘Šã€‚
å®ƒå¯¦ç¾äº†å ±å‘Šç”¢ç”Ÿèˆ‡ä¸»æ¥­å‹™é‚è¼¯çš„å®Œå…¨è§£è€¦ã€‚

ä½¿ç”¨æ–¹æ³•:
    python generate_report.py --db-file /path/to/your/database.db --config-file /path/to/your/config.json
"""
import sqlite3
import pandas as pd
from pathlib import Path
from datetime import datetime
import json
import pytz
import argparse
import sys
import sparklines
import re

class ReportGenerator:
    """
    å¾æŒ‡å®šçš„ SQLite è³‡æ–™åº«ç”Ÿæˆä¸‰ä»½æ¨™æº– Markdown å ±å‘Šã€‚
    """
    def __init__(self, db_path: Path, config_path: Path):
        if not db_path.exists():
            print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æŒ‡å®šçš„è³‡æ–™åº«æª”æ¡ˆ: {db_path}")
            sys.exit(1)
        if not config_path.exists():
            print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æŒ‡å®šçš„è¨­å®šæª”: {config_path}")
            sys.exit(1)

        self.db_path = db_path
        self.config = self._load_config(config_path)
        self.timezone = pytz.timezone(self.config.get("TIMEZONE", "Asia/Taipei"))
        self.df = None
        self.start_time = None
        self.end_time = None
        self.total_duration_seconds = 0
        self.output_dir = Path("logs")
        self.output_dir.mkdir(exist_ok=True)

    def _load_config(self, config_path: Path):
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def _load_data(self):
        """å¾è³‡æ–™åº«è¼‰å…¥æ•¸æ“šåˆ° pandas DataFrame"""
        with sqlite3.connect(self.db_path) as conn:
            self.df = pd.read_sql_query("SELECT * FROM phoenix_logs", conn)

        if self.df.empty:
            return

        self.df['timestamp'] = pd.to_datetime(self.df['timestamp']).dt.tz_localize('UTC').dt.tz_convert(self.timezone)
        self.df = self.df.set_index('timestamp')

        self.start_time = self.df.index.min()
        self.end_time = self.df.index.max()
        if pd.notna(self.start_time) and pd.notna(self.end_time):
            self.total_duration_seconds = (self.end_time - self.start_time).total_seconds()
        else:
            self.total_duration_seconds = 0


    def _format_duration(self, seconds: int) -> str:
        """å°‡ç§’æ•¸æ ¼å¼åŒ–ç‚º 'X åˆ† Y ç§’'"""
        seconds = int(seconds)
        minutes, seconds = divmod(seconds, 60)
        return f"{minutes} åˆ† {seconds} ç§’"

    def generate_all_reports(self):
        """ç”Ÿæˆæ‰€æœ‰å ±å‘Šä¸¦å¯«å…¥æª”æ¡ˆ"""
        print("ğŸš€ é–‹å§‹ç”Ÿæˆå ±å‘Š...")
        self._load_data()

        if self.df is None or self.df.empty:
            print("âš ï¸ æ²’æœ‰æ•¸æ“šå¯ä¾›ç”Ÿæˆå ±å‘Šã€‚")
            return

        # åœ¨ç”Ÿæˆå ±å‘Šå‰ï¼Œå…ˆé€²è¡Œäº‹ä»¶åˆ†æ
        top_events = self._analyze_events()

        reports = {
            "summary_report.md": lambda: self._generate_summary_report(top_events),
            "performance_report.md": self._generate_performance_report,
            "detailed_log_report.md": self._generate_log_report,
        }

        for filename, generator_func in reports.items():
            content = generator_func()
            report_path = self.output_dir / filename
            report_path.write_text(content, encoding='utf-8')
            print(f"âœ… å·²ç”Ÿæˆå ±å‘Š: {report_path}")

        print("ğŸ‰ æ‰€æœ‰å ±å‘Šå·²æˆåŠŸç”Ÿæˆã€‚")

    def _analyze_events(self) -> pd.DataFrame:
        """
        åˆ†ææ—¥èªŒä¸­çš„äº‹ä»¶ï¼Œè¨ˆç®—æ¯å€‹ä¸»è¦ä»»å‹™çš„è€—æ™‚ã€‚
        è¿”å›ä¸€å€‹åŒ…å«è€—æ™‚æœ€é•·ä»»å‹™çš„ DataFrameã€‚
        """
        if self.df.empty:
            return pd.DataFrame()

        # æˆ‘å€‘åªé—œå¿ƒ CMD å’Œ BATTLE ç­‰ç´šçš„æ—¥èªŒä¾†å®šç¾©ä»»å‹™é‚Šç•Œ
        task_logs = self.df[self.df['level'].isin(['CMD', 'BATTLE', 'SUCCESS', 'ERROR', 'CRITICAL'])].copy()

        events = []
        # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼ä¾†æ•æ‰æ›´é€šç”¨çš„æ¨¡å¼
        start_pattern = r"é–‹å§‹ç‚º (.*) å®‰è£"
        end_pattern = r"\[(.*)\] æ‰€æœ‰ä¾è³´å·²æˆåŠŸå®‰è£"

        # å°‹æ‰¾å®‰è£ä»»å‹™
        for index, log in task_logs.iterrows():
            # å°‹æ‰¾é–‹å§‹äº‹ä»¶
            match_start = re.search(start_pattern, log['message'])
            if match_start:
                app_name = match_start.group(1)
                start_time = index

                # å°‹æ‰¾å°æ‡‰çš„çµæŸäº‹ä»¶
                # é€™è£¡æˆ‘å€‘ç°¡åŒ–è™•ç†ï¼šå‡è¨­ä¸‹ä¸€å€‹ SUCCESS/ERROR æ˜¯å°æ‡‰çš„çµæŸ
                end_log = task_logs[
                    (task_logs.index > start_time) &
                    (task_logs['message'].str.contains(f"[{app_name}] æ‰€æœ‰ä¾è³´å·²æˆåŠŸå®‰è£") | task_logs['level'].isin(['ERROR', 'CRITICAL']))
                ].head(1)

                if not end_log.empty:
                    end_time = end_log.index[0]
                    duration = (end_time - start_time).total_seconds()
                    events.append({
                        "ä»»å‹™åç¨±": f"å®‰è£ {app_name} çš„ä¾è³´",
                        "è€—æ™‚ (ç§’)": duration,
                        "é–‹å§‹æ™‚é–“": start_time,
                        "çµæŸæ™‚é–“": end_time
                    })

        if not events:
            return pd.DataFrame()

        events_df = pd.DataFrame(events)
        return events_df.sort_values(by="è€—æ™‚ (ç§’)", ascending=False).head(5)

    def _generate_summary_report(self, top_events: pd.DataFrame) -> str:
        """ç”Ÿæˆç¶œåˆæˆ°æƒ…ç°¡å ±"""
        if self.df.empty: return "# ç¶œåˆæˆ°æƒ…ç°¡å ±\n\nç„¡æ•¸æ“šã€‚"

        # æ•ˆèƒ½æ‘˜è¦
        perf_df = self.df[self.df['level'] == 'PERF'].copy()
        avg_cpu = perf_df['cpu_usage'].mean() if not perf_df.empty else 0
        peak_cpu = perf_df['cpu_usage'].max() if not perf_df.empty else 0
        avg_ram = perf_df['ram_usage'].mean() if not perf_df.empty else 0
        peak_ram = perf_df['ram_usage'].max() if not perf_df.empty else 0

        # é—œéµäº‹ä»¶
        key_events = self.df[self.df['level'].isin(['SUCCESS', 'ERROR', 'WARN', 'BATTLE', 'CRITICAL'])].copy()

        # æœ€çµ‚ç‹€æ…‹
        has_errors = "ERROR" in self.df['level'].values or "CRITICAL" in self.df['level'].values
        status_color = "red" if has_errors else "green"
        status_text = "åŸ·è¡Œå®Œç•¢ï¼Œä½†æœ‰éŒ¯èª¤ç™¼ç”Ÿ" if has_errors else "ä»»å‹™æˆåŠŸ"

        md = f"""# ğŸ“‘ ç¶œåˆæˆ°æƒ…ç°¡å ±

**å ±å‘Šç”¢ç”Ÿæ™‚é–“:** {datetime.now(self.timezone).strftime('%Y-%m-%d %H:%M:%S %Z')}
**ç¸½è€—æ™‚:** {self._format_duration(self.total_duration_seconds)}

---

### ä¸€ã€ç¸½é«”çµæœ
**ç‹€æ…‹:** <font color="{status_color}">{status_text}</font>

### äºŒã€æ•ˆèƒ½é‡é»
- **å¹³å‡ CPU ä½¿ç”¨ç‡:** {avg_cpu:.1f}%
- **å³°å€¼ CPU ä½¿ç”¨ç‡:** {peak_cpu:.1f}%
- **å¹³å‡è¨˜æ†¶é«”ä½¿ç”¨ç‡:** {avg_ram:.1f}%
- **å³°å€¼è¨˜æ†¶é«”ä½¿ç”¨ç‡:** {peak_ram:.1f}%

### ä¸‰ã€è€—æ™‚æœ€é•·ä»»å‹™ Top 5
"""
        if not top_events.empty:
            md += top_events.to_markdown(index=False)
        else:
            md += "- ç„¡æ³•åˆ†æå…·é«”çš„ä»»å‹™è€—æ™‚ã€‚\n"

        md += "\n\n### å››ã€é—œéµäº‹ä»¶æ‘˜è¦\n"

        if not key_events.empty:
            for _, row in key_events.iterrows():
                md += f"- **[{row['level']}]** {row['message']}\n"
        else:
            md += "- ç„¡é—œéµäº‹ä»¶è¨˜éŒ„ã€‚\n"

        return md.strip()

    def _generate_performance_report(self) -> str:
        """ç”Ÿæˆè©³ç´°æ•ˆèƒ½å ±å‘Š"""
        if self.df.empty: return "# æ•ˆèƒ½åˆ†æå ±å‘Š\n\nç„¡æ•¸æ“šã€‚"

        perf_df = self.df[self.df['level'] == 'PERF'].copy()
        if perf_df.empty: return "# æ•ˆèƒ½åˆ†æå ±å‘Š\n\nç„¡æ•ˆèƒ½æ•¸æ“šã€‚"

        summary = {
            'CPU ä½¿ç”¨ç‡': (perf_df['cpu_usage'].mean(), perf_df['cpu_usage'].max(), perf_df['cpu_usage'].min()),
            'RAM ä½¿ç”¨ç‡': (perf_df['ram_usage'].mean(), perf_df['ram_usage'].max(), perf_df['ram_usage'].min())
        }

        cpu_trend = sparklines.sparklines(perf_df['cpu_usage'].tolist())[0]
        ram_trend = sparklines.sparklines(perf_df['ram_usage'].tolist())[0]

        md = f"""# ğŸ“Š æ•ˆèƒ½åˆ†æå ±å‘Š

**å ±å‘Šç”¢ç”Ÿæ™‚é–“:** {datetime.now(self.timezone).strftime('%Y-%m-%d %H:%M:%S %Z')}
**ç›£æ§æŒçºŒæ™‚é–“:** {self._format_duration(self.total_duration_seconds)}

---

### ä¸€ã€ç¸½é«”æ•ˆèƒ½æ‘˜è¦

| æŒ‡æ¨™ | å¹³å‡å€¼ | å³°å€¼ | æœ€ä½å€¼ | è¶¨å‹¢ (æ–‡å­—åœ–) |
|---|---|---|---|---|
| CPU ä½¿ç”¨ç‡ | {summary['CPU ä½¿ç”¨ç‡'][0]:.1f}% | {summary['CPU ä½¿ç”¨ç‡'][1]:.1f}% | {summary['CPU ä½¿ç”¨ç‡'][2]:.1f}% | `{cpu_trend}` |
| è¨˜æ†¶é«”ä½¿ç”¨ç‡ | {summary['RAM ä½¿ç”¨ç‡'][0]:.1f}% | {summary['RAM ä½¿ç”¨ç‡'][1]:.1f}% | {summary['RAM ä½¿ç”¨ç‡'][2]:.1f}% | `{ram_trend}` |

### äºŒã€è©³ç´°æ•¸æ“šè¡¨
{perf_df[['cpu_usage', 'ram_usage']].to_markdown()}
"""
        return md.strip()

    def _generate_log_report(self) -> str:
        """ç”Ÿæˆè©³ç´°æ—¥èªŒå ±å‘Š"""
        if self.df.empty: return "# è©³ç´°æ—¥èªŒå ±å‘Š\n\nç„¡æ•¸æ“šã€‚"

        log_df = self.df[self.df['level'] != 'PERF']
        if log_df.empty: return "# è©³ç´°æ—¥èªŒå ±å‘Š\n\nç„¡æ—¥èªŒæ•¸æ“šã€‚"

        md = f"""# ğŸ“ è©³ç´°æ—¥èªŒå ±å‘Š

**å ±å‘Šç”¢ç”Ÿæ™‚é–“:** {datetime.now(self.timezone).strftime('%Y-%m-%d %H:%M:%S %Z')}
**ä»»å‹™åŸ·è¡Œå€é–“:** {self.start_time.strftime('%Y-%m-%d %H:%M:%S')} - {self.end_time.strftime('%Y-%m-%d %H:%M:%S')}

---
```
{log_df[['level', 'message']].to_string()}
```
"""
        return md.strip()

if __name__ == "__main__":
    # ç¢ºä¿è…³æœ¬åŸ·è¡Œæ™‚ï¼Œå…¶ç›¸ä¾çš„æ ¸å¿ƒå¥—ä»¶éƒ½å·²å®‰è£
    try:
        import pandas
        import pytz
        import tabulate
    except ImportError:
        print("åµæ¸¬åˆ°ç¼ºå°‘å ±å‘Šç”Ÿæˆæ‰€éœ€çš„æ ¸å¿ƒä¾è³´ï¼Œè«‹å…ˆåŸ·è¡Œï¼š")
        print("pip install pandas pytz tabulate")
        sys.exit(1)

    parser = argparse.ArgumentParser(description="é³³å‡°ä¹‹å¿ƒ V16 å ±å‘Šç”Ÿæˆå™¨")
    parser.add_argument("--db-file", type=Path, required=True, help="ä¾†æº SQLite è³‡æ–™åº«çš„è·¯å¾‘")
    parser.add_argument("--config-file", type=Path, required=True, help="å°æ‡‰çš„ JSON è¨­å®šæª”è·¯å¾‘")
    args = parser.parse_args()

    generator = ReportGenerator(db_path=args.db_file, config_path=args.config_file)
    generator.generate_all_reports()
