# -*- coding: utf-8 -*-
"""
ç¨ç«‹å ±å‘Šç”Ÿæˆå™¨ (V16.1 - ç°¡åŒ–ä¾è³´)

é€™å€‹è…³æœ¬æ˜¯ä¸€å€‹ç¨ç«‹çš„å·¥å…·ï¼Œå°ˆé–€ç”¨ä¾†å¾ SQLite è³‡æ–™åº«ç”Ÿæˆæ¨™æº–çš„ Markdown å ±å‘Šã€‚
å®ƒå¯¦ç¾äº†å ±å‘Šç”¢ç”Ÿèˆ‡ä¸»æ¥­å‹™é‚è¼¯çš„å®Œå…¨è§£è€¦ã€‚
ç§»é™¤äº† sparklines å’Œ tabulate ä¾è³´ï¼Œä»¥æé«˜åœ¨ä»»ä½•ç’°å¢ƒä¸‹çš„å®‰è£æˆåŠŸç‡ã€‚

ä½¿ç”¨æ–¹æ³•:
    python generate_report.py --db-file /path/to/your/database.db --config-file /path/to/your/config.json
"""
import sqlite3
import pandas as pd
from pathlib import Path
from datetime import datetime
import json
import pytz
import argparse
import sys
import re

def df_to_markdown_table(df: pd.DataFrame) -> str:
    """æ‰‹å‹•å°‡ pandas DataFrame è½‰æ›ç‚º Markdown è¡¨æ ¼ï¼Œé¿å… tabulate ä¾è³´ã€‚"""
    if df.empty:
        return ""

    header = "| " + " | ".join(df.columns) + " |"
    separator = "| " + " | ".join(["---"] * len(df.columns)) + " |"
    body = "\n".join(["| " + " | ".join(map(str, row)) + " |" for row in df.itertuples(index=False)])

    return f"{header}\n{separator}\n{body}"

class ReportGenerator:
    """
    å¾æŒ‡å®šçš„ SQLite è³‡æ–™åº«ç”Ÿæˆä¸‰ä»½æ¨™æº– Markdown å ±å‘Šã€‚
    """
    def __init__(self, db_path: Path, config_path: Path):
        if not db_path.exists():
            print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æŒ‡å®šçš„è³‡æ–™åº«æª”æ¡ˆ: {db_path}")
            sys.exit(1)
        if not config_path.exists():
            print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æŒ‡å®šçš„è¨­å®šæª”: {config_path}")
            sys.exit(1)

        self.db_path = db_path
        self.config = self._load_config(config_path)
        self.timezone = pytz.timezone(self.config.get("TIMEZONE", "Asia/Taipei"))
        self.df = None
        self.start_time = None
        self.end_time = None
        self.total_duration_seconds = 0
        self.output_dir = Path("logs")
        self.output_dir.mkdir(exist_ok=True)

    def _load_config(self, config_path: Path):
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def _load_data(self):
        """å¾è³‡æ–™åº«è¼‰å…¥æ•¸æ“šåˆ° pandas DataFrame"""
        with sqlite3.connect(self.db_path) as conn:
            self.df = pd.read_sql_query("SELECT * FROM phoenix_logs", conn)

        if self.df.empty:
            return

        self.df['timestamp'] = pd.to_datetime(self.df['timestamp']).dt.tz_localize('UTC').dt.tz_convert(self.timezone)
        self.df = self.df.set_index('timestamp')

        self.start_time = self.df.index.min()
        self.end_time = self.df.index.max()
        if pd.notna(self.start_time) and pd.notna(self.end_time):
            self.total_duration_seconds = (self.end_time - self.start_time).total_seconds()
        else:
            self.total_duration_seconds = 0


    def _format_duration(self, seconds: int) -> str:
        """å°‡ç§’æ•¸æ ¼å¼åŒ–ç‚º 'X åˆ† Y ç§’'"""
        seconds = int(seconds)
        minutes, seconds = divmod(seconds, 60)
        return f"{minutes} åˆ† {seconds} ç§’"

    def generate_all_reports(self):
        """ç”Ÿæˆæ‰€æœ‰å ±å‘Šä¸¦å¯«å…¥æª”æ¡ˆ"""
        print("ğŸš€ é–‹å§‹ç”Ÿæˆå ±å‘Š...")
        self._load_data()

        if self.df is None or self.df.empty:
            print("âš ï¸ æ²’æœ‰æ•¸æ“šå¯ä¾›ç”Ÿæˆå ±å‘Šã€‚")
            return

        # åœ¨ç”Ÿæˆå ±å‘Šå‰ï¼Œå…ˆé€²è¡Œäº‹ä»¶åˆ†æ
        top_events = self._analyze_events()

        reports = {
            "summary_report.md": lambda: self._generate_summary_report(top_events),
            "performance_report.md": self._generate_performance_report,
            "detailed_log_report.md": self._generate_log_report,
        }

        for filename, generator_func in reports.items():
            content = generator_func()
            report_path = self.output_dir / filename
            report_path.write_text(content, encoding='utf-8')
            print(f"âœ… å·²ç”Ÿæˆå ±å‘Š: {report_path}")

        print("ğŸ‰ æ‰€æœ‰å ±å‘Šå·²æˆåŠŸç”Ÿæˆã€‚")

    def _analyze_events(self) -> pd.DataFrame:
        """
        åˆ†ææ—¥èªŒä¸­çš„äº‹ä»¶ï¼Œè¨ˆç®—æ¯å€‹ä¸»è¦ä»»å‹™çš„è€—æ™‚ã€‚
        è¿”å›ä¸€å€‹åŒ…å«è€—æ™‚æœ€é•·ä»»å‹™çš„ DataFrameã€‚
        """
        if self.df.empty:
            return pd.DataFrame()

        task_logs = self.df[self.df['level'].isin(['CMD', 'BATTLE', 'SUCCESS', 'ERROR', 'CRITICAL'])].copy()

        events = []
        start_pattern = r"é–‹å§‹ç‚º (.*) å®‰è£"

        for index, log in task_logs.iterrows():
            match_start = re.search(start_pattern, log['message'])
            if match_start:
                app_name = match_start.group(1)
                start_time = index
                end_log = task_logs[
                    (task_logs.index > start_time) &
                    (task_logs['message'].str.contains(f"[{app_name}] æ‰€æœ‰ä¾è³´å·²æˆåŠŸå®‰è£") | task_logs['level'].isin(['ERROR', 'CRITICAL']))
                ].head(1)

                if not end_log.empty:
                    end_time = end_log.index[0]
                    duration = (end_time - start_time).total_seconds()
                    events.append({
                        "ä»»å‹™åç¨±": f"å®‰è£ {app_name} çš„ä¾è³´",
                        "è€—æ™‚ (ç§’)": duration,
                        "é–‹å§‹æ™‚é–“": start_time.strftime('%H:%M:%S'),
                        "çµæŸæ™‚é–“": end_time.strftime('%H:%M:%S')
                    })

        if not events:
            return pd.DataFrame()

        events_df = pd.DataFrame(events)
        return events_df.sort_values(by="è€—æ™‚ (ç§’)", ascending=False).head(5)

    def _generate_summary_report(self, top_events: pd.DataFrame) -> str:
        """ç”Ÿæˆç¶œåˆæˆ°æƒ…ç°¡å ±"""
        if self.df.empty:
            return "# ç¶œåˆæˆ°æƒ…ç°¡å ±\n\nç„¡æ•¸æ“šã€‚"

        perf_df = self.df[self.df['level'] == 'PERF'].copy()
        avg_cpu = perf_df['cpu_usage'].mean() if not perf_df.empty else 0
        peak_cpu = perf_df['cpu_usage'].max() if not perf_df.empty else 0
        avg_ram = perf_df['ram_usage'].mean() if not perf_df.empty else 0
        peak_ram = perf_df['ram_usage'].max() if not perf_df.empty else 0

        key_events = self.df[self.df['level'].isin(['SUCCESS', 'ERROR', 'WARN', 'BATTLE', 'CRITICAL'])].copy()
        has_errors = "ERROR" in self.df['level'].values or "CRITICAL" in self.df['level'].values
        status_color = "red" if has_errors else "green"
        status_text = "åŸ·è¡Œå®Œç•¢ï¼Œä½†æœ‰éŒ¯èª¤ç™¼ç”Ÿ" if has_errors else "ä»»å‹™æˆåŠŸ"

        md = f"""# ğŸ“‘ ç¶œåˆæˆ°æƒ…ç°¡å ±

**å ±å‘Šç”¢ç”Ÿæ™‚é–“:** {datetime.now(self.timezone).strftime('%Y-%m-%d %H:%M:%S %Z')}
**ç¸½è€—æ™‚:** {self._format_duration(self.total_duration_seconds)}

---

### ä¸€ã€ç¸½é«”çµæœ
**ç‹€æ…‹:** <font color="{status_color}">{status_text}</font>

### äºŒã€æ•ˆèƒ½é‡é»
- **å¹³å‡ CPU ä½¿ç”¨ç‡:** {avg_cpu:.1f}%
- **å³°å€¼ CPU ä½¿ç”¨ç‡:** {peak_cpu:.1f}%
- **å¹³å‡è¨˜æ†¶é«”ä½¿ç”¨ç‡:** {avg_ram:.1f}%
- **å³°å€¼è¨˜æ†¶é«”ä½¿ç”¨ç‡:** {peak_ram:.1f}%

### ä¸‰ã€è€—æ™‚æœ€é•·ä»»å‹™ Top 5
"""
        if not top_events.empty:
            md += df_to_markdown_table(top_events)
        else:
            md += "- ç„¡æ³•åˆ†æå…·é«”çš„ä»»å‹™è€—æ™‚ã€‚\n"

        md += "\n\n### å››ã€é—œéµäº‹ä»¶æ‘˜è¦\n"
        if not key_events.empty:
            for _, row in key_events.iterrows():
                md += f"- **[{row['level']}]** {row['message']}\n"
        else:
            md += "- ç„¡é—œéµäº‹ä»¶è¨˜éŒ„ã€‚\n"

        return md.strip()

    def _generate_performance_report(self) -> str:
        """ç”Ÿæˆè©³ç´°æ•ˆèƒ½å ±å‘Š"""
        if self.df.empty:
            return "# æ•ˆèƒ½åˆ†æå ±å‘Š\n\nç„¡æ•¸æ“šã€‚"

        perf_df = self.df[self.df['level'] == 'PERF'].copy()
        if perf_df.empty:
            return "# æ•ˆèƒ½åˆ†æå ±å‘Š\n\nç„¡æ•ˆèƒ½æ•¸æ“šã€‚"

        summary = {
            'CPU ä½¿ç”¨ç‡': (perf_df['cpu_usage'].mean(), perf_df['cpu_usage'].max(), perf_df['cpu_usage'].min()),
            'RAM ä½¿ç”¨ç‡': (perf_df['ram_usage'].mean(), perf_df['ram_usage'].max(), perf_df['ram_usage'].min())
        }

        md = f"""# ğŸ“Š æ•ˆèƒ½åˆ†æå ±å‘Š

**å ±å‘Šç”¢ç”Ÿæ™‚é–“:** {datetime.now(self.timezone).strftime('%Y-%m-%d %H:%M:%S %Z')}
**ç›£æ§æŒçºŒæ™‚é–“:** {self._format_duration(self.total_duration_seconds)}

---

### ä¸€ã€ç¸½é«”æ•ˆèƒ½æ‘˜è¦

| æŒ‡æ¨™ | å¹³å‡å€¼ | å³°å€¼ | æœ€ä½å€¼ |
|---|---|---|---|
| CPU ä½¿ç”¨ç‡ | {summary['CPU ä½¿ç”¨ç‡'][0]:.1f}% | {summary['CPU ä½¿ç”¨ç‡'][1]:.1f}% | {summary['CPU ä½¿ç”¨ç‡'][2]:.1f}% |
| è¨˜æ†¶é«”ä½¿ç”¨ç‡ | {summary['RAM ä½¿ç”¨ç‡'][0]:.1f}% | {summary['RAM ä½¿ç”¨ç‡'][1]:.1f}% | {summary['RAM ä½¿ç”¨ç‡'][2]:.1f}% |

### äºŒã€è©³ç´°æ•¸æ“šè¡¨
"""
        # Manually format the detailed data table
        perf_df_display = perf_df[['cpu_usage', 'ram_usage']].copy()
        perf_df_display.index = perf_df_display.index.strftime('%Y-%m-%d %H:%M:%S')
        perf_df_display.reset_index(inplace=True)
        perf_df_display.rename(columns={'timestamp': 'æ™‚é–“', 'cpu_usage': 'CPU ä½¿ç”¨ç‡ (%)', 'ram_usage': 'RAM ä½¿ç”¨ç‡ (%)'}, inplace=True)
        md += df_to_markdown_table(perf_df_display.round(2))

        return md.strip()

    def _generate_log_report(self) -> str:
        """ç”Ÿæˆè©³ç´°æ—¥èªŒå ±å‘Š"""
        if self.df.empty:
            return "# è©³ç´°æ—¥èªŒå ±å‘Š\n\nç„¡æ•¸æ“šã€‚"

        log_df = self.df[self.df['level'] != 'PERF']
        if log_df.empty:
            return "# è©³ç´°æ—¥èªŒå ±å‘Š\n\nç„¡æ—¥èªŒæ•¸æ“šã€‚"

        md = f"""# ğŸ“ è©³ç´°æ—¥èªŒå ±å‘Š

**å ±å‘Šç”¢ç”Ÿæ™‚é–“:** {datetime.now(self.timezone).strftime('%Y-%m-%d %H:%M:%S %Z')}
**ä»»å‹™åŸ·è¡Œå€é–“:** {self.start_time.strftime('%Y-%m-%d %H:%M:%S')} - {self.end_time.strftime('%Y-%m-%d %H:%M:%S')}

---
```
"""
        # Manually format the log to avoid heavy dependencies
        for index, row in log_df.iterrows():
            md += f"[{index.strftime('%Y-%m-%d %H:%M:%S')}] [{row['level']}] {row['message']}\n"

        md += "```"
        return md.strip()

if __name__ == "__main__":
    try:
        parser = argparse.ArgumentParser(description="é³³å‡°ä¹‹å¿ƒ V16.1 å ±å‘Šç”Ÿæˆå™¨")
        parser.add_argument("--db-file", type=Path, required=True, help="ä¾†æº SQLite è³‡æ–™åº«çš„è·¯å¾‘")
        parser.add_argument("--config-file", type=Path, required=True, help="å°æ‡‰çš„ JSON è¨­å®šæª”è·¯å¾‘")
        args = parser.parse_args()

        print("å ±å‘Šç”Ÿæˆå™¨å·²å•Ÿå‹•...")
        generator = ReportGenerator(db_path=args.db_file, config_path=args.config_file)
        generator.generate_all_reports()
        print("å ±å‘Šç”Ÿæˆå™¨åŸ·è¡Œå®Œç•¢ã€‚")

    except Exception as e:
        import traceback
        print(f"âŒ å ±å‘Šç”Ÿæˆè…³æœ¬ç™¼ç”Ÿè‡´å‘½éŒ¯èª¤: {e}", file=sys.stderr)
        traceback.print_exc(file=sys.stderr)
        sys.exit(1)
